{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this article we are going to look into how you can track various experiments using Tensorboard in PyTorch and use the tracking data to tune hyperparameters. First let us see what is experiment tracking and hyperparameter tuning. \n",
    "\n",
    "### Experiment Tracking\n",
    "\n",
    "Experiment tracking refers to the process of collecting and organizing data related to machine learning experiments. It involves logging and monitoring various aspects of an experiment, such as the model architecture, hyperparameters, training progress, evaluation metrics, and visualizations.\n",
    "\n",
    "Experiment tracking helps researchers and practitioners keep a record of their experiments, making it easier to reproduce and compare results. It enables better understanding of the experiment's behavior, aids in debugging, and facilitates collaboration within teams.\n",
    "\n",
    "One popular tool for experiment tracking is TensorBoard, which is a web-based visualization tool provided by TensorFlow. While originally developed for TensorFlow, it can also be used with PyTorch, another popular deep learning framework.\n",
    "\n",
    "TensorBoard provides a user-friendly interface to explore and analyze experiment data. It allows visualizing metrics like loss and accuracy over time, examining the model graph, visualizing histograms of weights and biases, and displaying images and embeddings. It also supports interactive visualizations such as 3D embeddings and custom plots.\n",
    "\n",
    "By using TensorBoard, you can gain insights into your experiments, compare different models or hyperparameter settings, and make informed decisions for improving your machine learning models.\n",
    "\n",
    "### Hyper Parameter Tuning\n",
    "Hyperparameter tuning, also known as hyperparameter optimization, is the process of finding the optimal values for the hyperparameters of a machine learning model. Hyperparameters are configuration settings that are not learned from the data but are set prior to training and affect the learning process.\n",
    "\n",
    "Examples of hyperparameters include learning rate, batch size, number of hidden layers, number of units in each layer, regularization parameters, and activation functions. The choice of hyperparameters can significantly impact the performance and generalization ability of a model.\n",
    "\n",
    "Hyperparameter tuning is crucial because selecting appropriate values for hyperparameters can lead to better model performance. It involves systematically searching through a predefined space of possible hyperparameter values to find the combination that yields the best results.\n",
    "\n",
    "There are several strategies for hyperparameter tuning, including:\n",
    "\n",
    "1. Manual search: This involves manually selecting hyperparameter values based on prior knowledge, intuition, or trial and error. It is a simple approach but can be time-consuming and may not yield the best results.\n",
    "2. Grid search: Grid search involves defining a grid of possible hyperparameter values and exhaustively searching through all combinations. It evaluates and compares models trained with each combination of hyperparameters. While it guarantees finding the best hyperparameter values within the defined grid, it can be computationally expensive when the search space is large.\n",
    "3. Random search: Random search selects hyperparameter values randomly from a predefined distribution. It performs a specified number of random searches and evaluates the models trained with each set of hyperparameters. Random search is more efficient than grid search when the search space is large and it doesn't require exhaustive evaluation of all combinations.\n",
    "4. Bayesian optimization: Bayesian optimization is an advanced technique that uses probabilistic models to predict the performance of different hyperparameter settings. It iteratively explores the search space by evaluating a few carefully selected points and updating the probabilistic model. Bayesian optimization can be more efficient than random search or grid search when the search space is large and expensive to evaluate.\n",
    "5. Automated techniques: There are automated hyperparameter tuning techniques like genetic algorithms, evolutionary algorithms, and reinforcement learning-based approaches that aim to optimize hyperparameters automatically. These techniques use optimization algorithms to search the hyperparameter space based on fitness evaluation.\n",
    "\n",
    "During hyperparameter tuning, it is common to use evaluation metrics such as accuracy, precision, recall, or mean squared error to assess the performance of the models trained with different hyperparameter values.\n",
    "\n",
    "By tuning hyperparameters effectively, you can improve the performance and generalization of your machine learning models, leading to better results on unseen data. Experiment tracking tools like TensorBoard can be valuable in this process, as they allow you to monitor and compare the performance of different hyperparameter settings over time.\n",
    "\n",
    "For this demonstration we will be using the simple but expensive grid search. In the later blogs I will show you how we can implement the other hyperparameter tuning algorithms. \n",
    "\n",
    "We will use the FashionMNIST dataset and tune the hyperparamters of our custom VGG model using Grid Search. \n",
    "\n",
    "Let's begin."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q torchinfo torchmetrics tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision.transforms import Resize, Compose, ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import torchmetrics\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "if not os.path.exists(\"data\"): os.mkdir(\"data\")\n",
    "\n",
    "train_transform = Compose([Resize((64,64)),\n",
    "                           ToTensor()\n",
    "                           ])\n",
    "test_transform = Compose([Resize((64,64)),\n",
    "                          ToTensor()\n",
    "                          ])\n",
    "\n",
    "\n",
    "training_dataset = torchvision.datasets.FashionMNIST(root = \"data\",\n",
    "                                                     download = True,\n",
    "                                                     train = True,\n",
    "                                                     transform = train_transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root = \"data\",\n",
    "                                                 download = True,\n",
    "                                                 train = False,\n",
    "                                                 transform = test_transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True,\n",
    "                                          )\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size = BATCH_SIZE,\n",
    "                                              shuffle = False,\n",
    "                                              )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how many examples are there in the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images in test dataset is 10000\n",
      "Number of Images in training dataset is 60000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Images in test dataset is {len(test_dataset)}\")\n",
    "print(f\"Number of Images in training dataset is {len(training_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20d5921d7d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_dataset[0][0].permute((1,2,0)), cmap = \"gray\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TinyVGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyVGG(torch.nn.Module):\n",
    "  def __init__(self, in_channels, n_classes, hidden_units, n_conv_blocks, dropout):\n",
    "    super().__init__()\n",
    "    self.in_channels = in_channels\n",
    "    self.out_features = n_classes\n",
    "    self.dropout = dropout\n",
    "    self.hidden_units = hidden_units\n",
    "\n",
    "    self.input_block = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels = in_channels,\n",
    "                        out_channels=hidden_units,\n",
    "                        kernel_size = 3,\n",
    "                        padding = 0,\n",
    "                        stride = 1),\n",
    "        torch.nn.Dropout(dropout),\n",
    "        torch.nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    self.conv_block = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels = hidden_units,\n",
    "                        out_channels = hidden_units,\n",
    "                        kernel_size = 3,\n",
    "                        padding = 0,\n",
    "                        stride = 1),\n",
    "        torch.nn.Dropout(dropout),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "    )\n",
    "\n",
    "    self.classifier = torch.nn.Sequential(torch.nn.Flatten(),\n",
    "                                          torch.nn.LazyLinear(\n",
    "                                                          out_features = n_classes))\n",
    "\n",
    "    self.vgg_block = torch.nn.Sequential(self.input_block,\n",
    "                                         *[self.conv_block for _ in range(n_conv_blocks)],\n",
    "                                         self.classifier)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.vgg_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG                                  [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 10]                   --\n",
       "│    └─Sequential: 2-1                   [1, 16, 62, 62]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 16, 62, 62]           160\n",
       "│    │    └─Dropout: 3-2                 [1, 16, 62, 62]           --\n",
       "│    │    └─ReLU: 3-3                    [1, 16, 62, 62]           --\n",
       "│    └─Sequential: 2-2                   [1, 16, 30, 30]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 16, 60, 60]           2,320\n",
       "│    │    └─Dropout: 3-5                 [1, 16, 60, 60]           --\n",
       "│    │    └─ReLU: 3-6                    [1, 16, 60, 60]           --\n",
       "│    │    └─MaxPool2d: 3-7               [1, 16, 30, 30]           --\n",
       "│    └─Sequential: 2-3                   [1, 16, 14, 14]           (recursive)\n",
       "│    │    └─Conv2d: 3-8                  [1, 16, 28, 28]           (recursive)\n",
       "│    │    └─Dropout: 3-9                 [1, 16, 28, 28]           --\n",
       "│    │    └─ReLU: 3-10                   [1, 16, 28, 28]           --\n",
       "│    │    └─MaxPool2d: 3-11              [1, 16, 14, 14]           --\n",
       "│    └─Sequential: 2-4                   [1, 16, 6, 6]             (recursive)\n",
       "│    │    └─Conv2d: 3-12                 [1, 16, 12, 12]           (recursive)\n",
       "│    │    └─Dropout: 3-13                [1, 16, 12, 12]           --\n",
       "│    │    └─ReLU: 3-14                   [1, 16, 12, 12]           --\n",
       "│    │    └─MaxPool2d: 3-15              [1, 16, 6, 6]             --\n",
       "│    └─Sequential: 2-5                   [1, 10]                   --\n",
       "│    │    └─Flatten: 3-16                [1, 576]                  --\n",
       "│    │    └─Linear: 3-17                 [1, 10]                   5,770\n",
       "==========================================================================================\n",
       "Total params: 8,250\n",
       "Trainable params: 8,250\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 11.13\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 1.07\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 1.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  TinyVGG(in_channels = 1,\n",
    "                 n_classes = len(training_dataset.classes),\n",
    "                 hidden_units = 16,\n",
    "                 n_conv_blocks = 3,\n",
    "                 dropout = 0.1).to(device)\n",
    "summary(model, [1,64,64], batch_dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, there are several hyperparameters as you can see - Learning Rate, Number of Epochs, type of optimizer, number of convolution layers, dropout and number of hidden units. We can first fix the learning rate and number of epoch and try to find the best optimizer, convolution layers, dropout and hidden units. Once we have those we can then tune the number of epochs and learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_config = {\n",
    "    \"n_conv_layers\" : [2, 4, 6],\n",
    "    \"dropout\": [0.1, 0.2],\n",
    "    \"optimizer\": ['adam', 'sgd'],\n",
    "    \"hidden_units\": [8, 10, 12, 16]\n",
    "}\n",
    "\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 2 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 4 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.1 || Optimizer: adam || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.1 || Optimizer: sgd || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.2 || Optimizer: adam || Hidden Units: 16\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 8\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 10\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 12\n",
      "Tuning HyperParameters || Number of Conv Layers: 6 || Dropout: 0.2 || Optimizer: sgd || Hidden Units: 16\n"
     ]
    }
   ],
   "source": [
    "for n_conv_layers in hparams_config[\"n_conv_layers\"]:\n",
    "    for dropout in hparams_config[\"dropout\"]:\n",
    "        for optimizer in hparams_config[\"optimizer\"]:\n",
    "            for hidden_units in hparams_config[\"hidden_units\"]:\n",
    "                print(\n",
    "                    f\"Tuning HyperParameters || Number of Conv Layers: {n_conv_layers} || Dropout: {dropout} || Optimizer: {optimizer} || Hidden Units: {hidden_units}\"\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
